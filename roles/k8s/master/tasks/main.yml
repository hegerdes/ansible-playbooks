# Main k8s Setup
---
- name: Test reachability to shared KubeControlPlaneHost
  shell: 'ping -c 5 {{ k8s_shared_api_server_endpoint }}'
  changed_when: false
  tags: [k8s, k8-init, k8-master-init]

- name: Check if kubeadm has already run
  when: groups.k8s_master | flatten | first == inventory_hostname
  stat:
    path: "/etc/kubernetes/pki/ca.key"
  register: kubeadm_ca
  tags: [k8s, k8-init, k8-master-init]

- name: Generate certificat key
  when: groups.k8s_master | flatten | first == inventory_hostname
  shell: kubeadm certs certificate-key
  register: k8s_kubeadm_cert_key_res
  run_once: true
  tags: [k8s, k8-init, k8-master-init]

- name: Save certificat key
  when: groups.k8s_master | flatten | first == inventory_hostname
  set_fact:
    k8s_kubeadm_cert_key: '{{ k8s_kubeadm_cert_key_res.stdout }}'
  run_once: true
  tags: [k8s, k8-init, k8-master-init]

- name: Init cluster if needed
  when: groups.k8s_master | flatten | first == inventory_hostname and not kubeadm_ca.stat.exists
  include_tasks: kubeadm-init.yml
  tags: [k8s, k8-init, k8-master-init]

- name: Get ControlPlane join Command
  when: groups.k8s_master | flatten | first == inventory_hostname
  command: kubeadm token create --print-join-command
  register: tmp_k8_join_command
  changed_when: false
  run_once: true
  tags: [k8s, k8s-init, k8-master-init]

- name: Setting join command for all master-nodes
  when: groups.k8s_master | flatten | first == inventory_hostname
  run_once: true
  set_fact:
    k8_cp_join_command: '{{ tmp_k8_join_command.stdout }} --control-plane --certificate-key {{ k8_cert_key if(k8_cert_key != "none") else k8s_kubeadm_cert_key }}'
  delegate_to: "{{ item }}"
  with_items: "{{ play_hosts }}"
  tags: [k8s, k8s-init, k8-master-init]

- name: Debug - Print join command
  debug:
    msg: |
      {{ k8_cp_join_command }} \
        --apiserver-advertise-address={{ ansible_facts.all_ipv4_addresses | ansible.utils.reduce_on_network(k8s_cloud_subnet) | first if(k8s_cloud_subnet | default("none") != "none") else k8s_kubelet_advertise_address_bind | default(ansible_facts.default_ipv4.address) }}
  run_once: true
  tags: [k8s, k8-init, k8-master-init]

- name: Check if kubeadm has already run
  stat:
    path: /etc/kubernetes/kubelet.conf
  register: k8s_kubeadm_all_init
  tags: [k8s, k8-init, k8-master-init]

- name: Join ControlPlane nodes
  when: not k8s_kubeadm_all_init.stat.exists
  command: '{{ k8_cp_join_command }} --apiserver-advertise-address={{ ansible_facts.all_ipv4_addresses | ansible.utils.reduce_on_network(k8s_cloud_subnet) | first if(k8s_cloud_subnet | default("none") != "none") else k8s_kubelet_advertise_address_bind | default(ansible_facts.default_ipv4.address) }}'
  tags: [k8s, k8s-init, k8-master-init]
  register: k8s_join_res

- name: Enable and check kubelet service
  systemd:
    name: kubelet
    daemon_reload: yes
    state: started
    enabled: yes
  ignore_errors: '{{ ansible_check_mode }}'
  tags: [k8s, k8-init, k8-master-init]

- name: Show join results
  debug:
    var: k8s_join_res
  tags: [k8s, k8-init, k8-master-init]

- name: Remove no NoSchedule taint form master nodes
  kubernetes.core.k8s_taint:
    kubeconfig: '{{ k8s_kubeconfig | default("/etc/kubernetes/admin.conf") }}'
    state: absent
    name: '{{ ansible_facts.hostname }}'
    taints:
    - key: node-role.kubernetes.io/control-plane
      effect: NoSchedule
    - key: node-role.kubernetes.io/master
      effect: NoSchedule
    - key: node.cloudprovider.kubernetes.io/uninitialized
      effect: NoSchedule
    - key: dedicated
  tags: [k8s, k8-init, k8-master-init, k8-taint]

- name: Setting taints
  kubernetes.core.k8s_taint:
    kubeconfig: '{{ k8s_kubeconfig | default("/etc/kubernetes/admin.conf") }}'
    state: '{{ item.state | default("present") }}'
    name: '{{ item.node }}'
    taints:
    - key: '{{ item.key }}'
      effect: '{{ item.effect | default(omit) }}'
  loop: '{{ k8s_taints }}'
  tags: [k8s, k8-init, k8-master-init, k8-taint]

- name: Setup configs
  include_tasks: setup-configs.yml
  tags: [k8s, k8-init, k8-master-init, k8s-init-config]

- name: Install Helm
  include_role:
    name: k8s/helm
    public: yes
  tags: [k8s, k8s-init, k8-master-init, k8s-helm]

- name: Setup CNI
  when: groups.k8s_master | flatten | first == inventory_hostname
  include_tasks: 'setup-cni-{{ k8s_cni | lower }}.yml'
  tags: [k8s, k8-init, k8-master-init, k8-cri, k8s-flannel, k8s-calico, k8s-cilium, k8s-weave]

- name: Setup k9s
  when: k8s_install_k9s
  include_tasks: 'setup-k9s.yml'
  tags: [k8s, k8-init, k8-master-init, k8s-k9s]

# - name: Kubeadm check
#   shell: kubectl cluster-info
#   register: k8s_cluster_info
#   tags: [k8s, k8-init, k8-master-init]

# - name: Debug - Print cluser info
#   debug:
#     var: k8s_cluster_info.stderr_lines + k8s_cluster_info.stdout_lines
#   run_once: true
#   tags: [k8s, k8-init, k8-master-init]

# - name: Ensure handlers are notified now
#   meta: flush_handlers
